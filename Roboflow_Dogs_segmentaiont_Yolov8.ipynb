{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bd0076-153b-4007-a953-05d2a3ae22cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 경로: D:\\Python_Pytorch_Workspace\\Jupyter_Test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script uses YOLOv8 by Ultralytics.\n",
    "YOLOv8 is distributed under the AGPL-3.0 License.\n",
    "For more details, visit: https://github.com/ultralytics/ultralytics\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# 작업 경로 설정\n",
    "base_path = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\"\n",
    "\n",
    "# 경로 생성 (존재하지 않으면 생성)\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# 현재 작업 디렉토리 변경\n",
    "os.chdir(base_path)\n",
    "\n",
    "# 확인\n",
    "print(f\"현재 작업 경로: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61397aae-d995-41fc-88c3-953b63cdd204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 10 07:22:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   48C    P8              7W /  160W |    1702MiB /   8188MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1000    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A      1016    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A      3228    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      4548    C+G   ...010.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A      5856    C+G   ...B\\system_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A      6964    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A      7636    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9836    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A      9924    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10152    C+G   ....0_x64__8wekyb3d8bbwe\\onenoteim.exe      N/A      |\n",
      "|    0   N/A  N/A     12856    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     13288    C+G   ...n\\131.0.2903.112\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     13792    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     16052    C+G   ...010.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A     16268    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     16288    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17112    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     20012    C+G   ...ogram Files\\Notepad++\\notepad++.exe      N/A      |\n",
      "|    0   N/A  N/A     20076    C+G   ...s\\Toolbox\\bin\\jetbrains-toolbox.exe      N/A      |\n",
      "|    0   N/A  N/A     20512    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     20784    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     21924    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e823d4-37d2-4aa1-a5c0-cd6ba575d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (8.3.57)\n",
      "Requirement already satisfied: numpy>=1.23.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (3.5.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (2.5.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319d9321-33cd-42df-80de-86bb79961a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\n",
      "\u001b[2K\n",
      "Ultralytics 8.3.57 �윓� Python-3.10.16 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Setup complete �쐟 (12 CPUs, 31.6 GB RAM, 18.2/489.0 GB disk)\n",
      "\n",
      "OS                  Windows-10-10.0.26100-SP0\n",
      "Environment         Windows\n",
      "Python              3.10.16\n",
      "Install             pip\n",
      "RAM                 31.62 GB\n",
      "Disk                18.2/489.0 GB\n",
      "CPU                 AMD Ryzen 5 7500F 6-Core Processor\n",
      "CPU count           12\n",
      "GPU                 NVIDIA GeForce RTX 4060 Ti, 8188MiB\n",
      "GPU count           1\n",
      "CUDA                12.4\n",
      "\n",
      "numpy               �쐟 1.26.4>=1.23.0\n",
      "numpy               �쐟 1.26.4<2.0.0; sys_platform == \"darwin\"\n",
      "matplotlib          �쐟 3.5.3>=3.3.0\n",
      "opencv-python       �쐟 4.10.0.84>=4.6.0\n",
      "pillow              �쐟 9.4.0>=7.1.2\n",
      "pyyaml              �쐟 6.0.1>=5.3.1\n",
      "requests            �쐟 2.31.0>=2.23.0\n",
      "scipy               �쐟 1.14.1>=1.4.1\n",
      "torch               �쐟 2.5.0>=1.8.0\n",
      "torch               �쐟 2.5.0!=2.4.0,>=1.8.0; sys_platform == \"win32\"\n",
      "torchvision         �쐟 0.20.0>=0.9.0\n",
      "tqdm                �쐟 4.67.1>=4.64.0\n",
      "psutil              �쐟 6.1.1\n",
      "py-cpuinfo          �쐟 9.0.0\n",
      "pandas              �쐟 1.5.3>=1.1.4\n",
      "seaborn             �쐟 0.12.2>=0.11.0\n",
      "ultralytics-thop    �쐟 2.0.13>=2.0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script uses YOLOv8 by Ultralytics.\n",
    "YOLOv8 is distributed under the AGPL-3.0 License.\n",
    "For more details, visit: https://github.com/ultralytics/ultralytics\n",
    "\"\"\"\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4dc1a86-8b8c-4685-b699-ed3a3410df87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   903  100   903    0     0   1588      0 --:--:-- --:--:-- --:--:--  1589\n",
      "100   903  100   903    0     0   1588      0 --:--:-- --:--:-- --:--:--  1589\n",
      "\n",
      "  2 1530k    2 32721    0     0  25182      0  0:01:02  0:00:01  0:01:01 25182\n",
      " 44 1530k   44  682k    0     0   304k      0  0:00:05  0:00:02  0:00:03  687k\n",
      "100 1530k  100 1530k    0     0   621k      0  0:00:02  0:00:02 --:--:-- 1287k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o \"{base_path}\\Dogs.zip\" \"https://app.roboflow.com/ds/PtCGN1RfcU?key=Zp3yVDG1et\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9982d2e-9440-4f3e-96fe-7cc62cf02c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축이 해제되었습니다: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# ZIP 파일 경로\n",
    "# zip_file_path = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dog_Cat_Data.zip\"\n",
    "zip_path = os.path.join(base_path, \"Dogs.zip\")\n",
    "# 압축을 해제할 대상 경로\n",
    "# extract_to_path = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dog_Cat_Data\"\n",
    "extract_path = os.path.join(base_path, \"Dogs_DataSet\")\n",
    "\n",
    "# 경로 생성 (존재하지 않으면 생성)\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# ZIP 파일 열고 압축 해제\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"압축이 해제되었습니다: {extract_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4493f9-503e-45ec-83dd-5fd4da680c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (6.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bfccb65-b4d1-4990-845d-5a31a385ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 경로: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\data.yaml\n",
      "{'train': '../train/images', 'val': '../valid/images', 'test': '../test/images', 'nc': 1, 'names': ['dogs-and-cats'], 'roboflow': {'workspace': 'pytorchyololabelingworkbusanit', 'project': 'segmentaion_test_demo', 'version': 1, 'license': 'CC BY 4.0', 'url': 'https://universe.roboflow.com/pytorchyololabelingworkbusanit/segmentaion_test_demo/dataset/1'}}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# 기본 경로 설정, 위에 정의 \n",
    "# base_path = r\"C:\\Aquarium_DataSet\"\n",
    "data_yaml_path = os.path.join(base_path, \"Dogs_DataSet\")\n",
    "# 파일 경로 출력\n",
    "file_name = \"data.yaml\"\n",
    "file_path = os.path.join(data_yaml_path, file_name)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"파일 경로: {file_path}\")\n",
    "    # YAML 파일 읽기 및 출력\n",
    "    with open(file_path, 'r') as f:\n",
    "        print(yaml.safe_load(f))\n",
    "else:\n",
    "    print(f\"{file_name} 파일이 {base_path}에 존재하지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e85e9209-62da-446a-ad49-eea5ddc28367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['dogs-and-cats'], 'nc': 1, 'test': 'D:\\\\Python_Pytorch_Workspace\\\\Jupyter_Test\\\\Dogs_DataSet\\\\test\\\\images\\\\\\\\', 'train': 'D:\\\\Python_Pytorch_Workspace\\\\Jupyter_Test\\\\Dogs_DataSet\\\\train\\\\images\\\\\\\\', 'val': 'D:\\\\Python_Pytorch_Workspace\\\\Jupyter_Test\\\\Dogs_DataSet\\\\valid\\\\images\\\\\\\\'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# 데이터 정의\n",
    "data = {\n",
    "  'train': r'D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\train\\images\\\\',\n",
    "  'val': r'D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\valid\\images\\\\',\n",
    "  'test': r'D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\test\\images\\\\',\n",
    "  'names': ['dogs-and-cats'],\n",
    "  'nc': 1\n",
    "}\n",
    "\n",
    "# YAML 파일 작성\n",
    "yaml_file_path = r'D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\data2.yaml'\n",
    "\n",
    "with open(yaml_file_path, 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "# YAML 파일 읽기 및 출력\n",
    "with open(yaml_file_path, 'r') as f:\n",
    "    print(yaml.safe_load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef8ff1b-ccde-4e17-8788-40dd0af4ae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.57  Python-3.10.16 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Setup complete  (12 CPUs, 31.6 GB RAM, 18.2/489.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f667725d-1af6-427b-9960-305a5a2887d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n",
      "Device Name: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac524321-c42c-4d64-b4db-45e46f2d6107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 6.74M/6.74M [00:00<00:00, 24.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa9d03b-3894-48a0-b244-97410a2a2263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 80\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(type(model.names), len(model.names))\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae27681-919b-4e63-8f96-9b6ebbe82a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.59 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.57  Python-3.10.16 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\data2.yaml, epochs=100, time=None, patience=30, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=D:\\Python_Pytorch_Workspace\\Jupyter_Test, name=modelresult4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3,263,811 parameters, 3,263,795 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\train\\labels... 17 images, 0 backgrounds, 0 c\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\valid\\labels... 5 images, 0 backgrounds, 0 corr\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.27G     0.6273      2.168      2.325      1.083         63        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1       0.62      0.487      0.008          1        0.6      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      1.28G     0.7344      2.332        2.4       1.11         74        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.655       0.49      0.008          1      0.629      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      1.26G      0.944      3.518      2.518      1.243         65        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1       0.67       0.53      0.008          1      0.643      0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      1.28G     0.9869      2.828      2.547      1.279         75        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.687      0.545      0.008          1      0.662      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      1.28G     0.8206      2.508      2.409      1.145         65        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.693      0.545    0.00733      0.917      0.674      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      1.28G      0.848      2.531      2.549      1.143         79        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.769      0.617      0.008          1      0.758      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      1.32G     0.9919      2.775      2.514      1.238         87        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1       0.76      0.689      0.008          1      0.754      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      1.31G     0.6581       1.83      2.229      1.072         70        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.754      0.647      0.008          1      0.751      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      1.31G     0.6969      1.539      2.233      1.047         76        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.836      0.636      0.008          1      0.768      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      1.31G     0.7815      1.339      1.953      1.106         65        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.755      0.568      0.008          1      0.753      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      1.31G     0.5834      1.293      1.852      1.029         90        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1       0.78      0.525      0.008          1      0.738      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      1.31G     0.6866      1.446      1.699      1.084         74        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.751       0.47      0.008          1      0.761       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      1.31G     0.5725      1.237      1.491     0.9857         68        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.044          1      0.822      0.465     0.0403      0.917      0.719      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100       1.3G     0.6373      1.295      1.479          1         77        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.797      0.583      0.757      0.452      0.886       0.65      0.755      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100       1.3G      0.586      1.076      1.366     0.9748         62        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.846      0.461      0.818      0.457      0.846      0.461      0.777      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      1.31G     0.6419      1.296      1.312      1.031         76        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.858      0.506      0.826      0.438      0.858      0.506      0.785      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      1.33G     0.5397     0.9672       1.23     0.9743         78        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12       0.86      0.514      0.747      0.436       0.86      0.514      0.774       0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      1.31G     0.5197     0.9281      1.044     0.9772         70        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.859      0.507       0.71      0.406      0.859      0.507       0.75      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      1.31G     0.6666      1.122      1.102      1.042         67        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.863      0.528      0.658       0.39      0.863      0.528      0.713      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      1.31G     0.5075     0.8577      1.018     0.9421         63        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.855      0.494      0.654      0.396      0.855      0.494       0.65      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      1.29G     0.5301     0.9195      1.118     0.9749         63        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12       0.85      0.475       0.67       0.41       0.85      0.475      0.654      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      1.33G     0.6366      1.029      1.026      1.027         84        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.841      0.417      0.666       0.43      0.841      0.417       0.66      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      1.31G     0.5501      1.072     0.9471     0.9757         69        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12       0.96      0.583      0.705      0.421      0.863      0.527      0.671      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      1.33G     0.5658     0.9716     0.8876     0.9796         89        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.942      0.583       0.74      0.454      0.942      0.583      0.739      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      1.29G     0.5329     0.8498     0.9746     0.9964         55        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.945      0.667      0.747       0.42      0.945      0.667      0.742       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100       1.3G      0.583     0.7982     0.7751      1.003         75        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.887      0.657      0.737      0.392      0.887      0.657      0.734      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      1.31G     0.5958     0.9329     0.9082     0.9876         68        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.874      0.581      0.714       0.37      0.874      0.581       0.71      0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      1.31G     0.5623     0.8431      0.851      0.979         66        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.765      0.545      0.634       0.34      0.765      0.545       0.63      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      1.31G      0.603     0.8029     0.8829     0.9835         72        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1      0.404       0.52      0.284          1      0.404      0.554      0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      1.29G     0.5839     0.9267      0.922     0.9958         52        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.712      0.417      0.511      0.212      0.705      0.417      0.563      0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100       1.3G     0.7049      1.006      1.015      1.054         71        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.918      0.333      0.441      0.205          1      0.368      0.536      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      1.29G     0.6363      1.232     0.8824      1.034         58        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1      0.312      0.525      0.243          1      0.315      0.515      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      1.31G     0.5563     0.7629     0.8431      1.011         77        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1      0.234       0.57      0.269          1      0.234      0.467      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      1.31G     0.5445     0.9048     0.8067      1.005         70        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1      0.166      0.436      0.232          1      0.166      0.365      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      1.28G     0.5287     0.9314     0.9321      1.004         59        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1      0.164      0.398      0.186          1      0.164      0.358       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      1.31G     0.5498     0.7362     0.8148      1.003         74        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1      0.165      0.482      0.264          1      0.165      0.379      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      1.31G       0.51      0.757     0.7877     0.9323         72        416: 100%|██████████| 1/1 [00:\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12          1       0.23      0.477      0.299          1       0.23      0.473      0.285\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 7, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "37 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\\weights\\last.pt, 6.7MB\n",
      "Optimizer stripped from D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\\weights\\best.pt, 6.7MB\n",
      "\n",
      "Validating D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\\weights\\best.pt...\n",
      "Ultralytics 8.3.57  Python-3.10.16 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5         12      0.008          1      0.757      0.685      0.008          1       0.75      0.658\n",
      "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\u001b[0m\n",
      "저장된 경로: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresult4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# YOLOv8 학습 실행\n",
    "results = model.train(\n",
    "    data=r'D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_DataSet\\data2.yaml',  # 데이터 경로\n",
    "    epochs=100,\n",
    "    patience=30,\n",
    "    batch=32,\n",
    "    imgsz=416,\n",
    "    project=r'D:\\Python_Pytorch_Workspace\\Jupyter_Test',  # 프로젝트 경로 지정\n",
    "    name='modelresult'  # 실험 이름 지정\n",
    ")\n",
    "# 결과 확인\n",
    "if results is not None and hasattr(results, 'save_dir'):\n",
    "    default_save_path = results.save_dir\n",
    "    print(f\"저장된 경로: {default_save_path}\")\n",
    "else:\n",
    "    # 결과가 None인 경우 기본 경로 확인\n",
    "    default_save_path = os.path.join(r'D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Dogs_Test', 'modelresult')\n",
    "    print(f\"결과 객체가 None이므로 기본 경로를 사용합니다: {default_save_path}\")\n",
    "\n",
    "\n",
    "# 저장된 경로 확인\n",
    "# default_save_path = results.save_dir\n",
    "\n",
    "# # 디렉토리 확인 및 가장 최근 실험 선택\n",
    "# if os.path.exists(default_save_path) and os.listdir(default_save_path):\n",
    "#     experiment_dirs = sorted(os.listdir(default_save_path))\n",
    "#     experiment_name = experiment_dirs[-1]\n",
    "#     experiment_path = os.path.join(default_save_path, experiment_name)\n",
    "#     print(f\"가장 최근 실험 디렉토리 경로: {experiment_path}\")\n",
    "# else:\n",
    "#     print(f\"'{default_save_path}' 경로에 실험 디렉토리가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42f23f6c-a9c6-4a8d-b673-02365ed0366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 1\n",
      "{0: 'dogs-and-cats'}\n"
     ]
    }
   ],
   "source": [
    "print(type(model.names), len(model.names))\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22a5df36-84cb-45a3-8858-4ee1bce66275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ultralytics\n",
      "Version: 8.3.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 185, in print_results\n",
      "    write_output(\"Summary: %s\", dist.summary)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Summary: %s'\n",
      "Arguments: ('Ultralytics YOLO \\U0001f680 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 186, in print_results\n",
      "    write_output(\"Home-page: %s\", dist.homepage)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Home-page: %s'\n",
      "Arguments: ('https://ultralytics.com',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 187, in print_results\n",
      "    write_output(\"Author: %s\", dist.author)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Author: %s'\n",
      "Arguments: ('',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 188, in print_results\n",
      "    write_output(\"Author-email: %s\", dist.author_email)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Author-email: %s'\n",
      "Arguments: ('Glenn Jocher <glenn.jocher@ultralytics.com>, Jing Qiu <jing.qiu@ultralytics.com>',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 189, in print_results\n",
      "    write_output(\"License: %s\", dist.license)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'License: %s'\n",
      "Arguments: ('AGPL-3.0',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 190, in print_results\n",
      "    write_output(\"Location: %s\", dist.location)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Location: %s'\n",
      "Arguments: ('d:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 195, in print_results\n",
      "    write_output(\"Requires: %s\", \", \".join(dist.requires))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Requires: %s'\n",
      "Arguments: ('matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, torch, torchvision, tqdm, ultralytics-thop',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 1673, in print\n",
      "    with self:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 865, in __exit__\n",
      "    self._exit_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 823, in _exit_buffer\n",
      "    self._check_buffer()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\console.py\", line 2027, in _check_buffer\n",
      "    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py\", line 19, in legacy_windows_render\n",
      "    term.write_text(text)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py\", line 403, in write_text\n",
      "    self.write(text)\n",
      "UnicodeEncodeError: 'cp949' codec can't encode character '\\U0001f680' in position 26: illegal multibyte sequence\n",
      "Call stack:\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 157, in main\n",
      "    return self._main(args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 231, in _main\n",
      "    return self._run_wrapper(level_number, options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 46, in run\n",
      "    if not print_results(\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\commands\\show.py\", line 196, in print_results\n",
      "    write_output(\"Required-by: %s\", \", \".join(dist.required_by))\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 379, in write_output\n",
      "    logger.info(msg, *args)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\logging\\__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pip\\_internal\\utils\\logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: 'Required-by: %s'\n",
      "Arguments: ('',)\n"
     ]
    }
   ],
   "source": [
    "!pip show ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a98fb228-baf7-4dba-a476-ecd42b3b97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Python_Pytorch_Workspace\\Jupyter_Test\\dog-cat2.png: 416x384 (no detections), 36.0ms\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mD:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg_Dogs2\u001b[0m\n",
      "0 label saved to D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg_Dogs2\\labels\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'dogs-and-cats'}\n",
      "obb: None\n",
      "orig_img: array([[[ 95, 105, 131],\n",
      "        [ 95, 105, 131],\n",
      "        [ 94, 101, 126],\n",
      "        ...,\n",
      "        [ 50,  63,  89],\n",
      "        [ 34,  48,  74],\n",
      "        [ 17,  43,  70]],\n",
      "\n",
      "       [[ 93, 102, 129],\n",
      "        [ 91, 100, 126],\n",
      "        [ 93, 100, 125],\n",
      "        ...,\n",
      "        [ 77,  91, 117],\n",
      "        [ 37,  50,  76],\n",
      "        [ 17,  43,  70]],\n",
      "\n",
      "       [[ 91, 100, 126],\n",
      "        [ 87,  96, 123],\n",
      "        [ 88,  96, 120],\n",
      "        ...,\n",
      "        [ 93, 105, 131],\n",
      "        [ 48,  59,  86],\n",
      "        [ 10,  33,  58]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (308, 281)\n",
      "path: 'D:\\\\Python_Pytorch_Workspace\\\\Jupyter_Test\\\\dog-cat2.png'\n",
      "probs: None\n",
      "save_dir: 'D:\\\\Python_Pytorch_Workspace\\\\Jupyter_Test\\\\modelresultImg_Dogs2'\n",
      "speed: {'preprocess': 2.000093460083008, 'inference': 35.99905967712402, 'postprocess': 0.0}]\n",
      "결과 이미지가 다음 경로에 저장되었습니다: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 저장 경로 생성\n",
    "save_dir = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg_Dogs\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# YOLOv8 모델로 예측 실행\n",
    "results = model.predict(\n",
    "    source=r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\dog-cat2.png\",  # 테스트 이미지 경로\n",
    "    save=True,  # 결과 저장 활성화\n",
    "    project=r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\",  # 저장될 프로젝트 경로\n",
    "    name=\"modelresultImg_Dogs\",  # 저장 디렉토리 이름\n",
    "    conf=0.25,  # 예측 확률 임계값 설정\n",
    "    save_txt=True,  # 예측 결과 텍스트로 저장\n",
    "    save_conf=True,  # 결과 이미지에 확률값 표시\n",
    "#     visualize=True  # 시각화 활성화\n",
    "#     line_thickness=2  # 경계 상자 두께 설정\n",
    ")\n",
    "print(results)\n",
    "\n",
    "# 저장 경로 확인\n",
    "default_save_path = os.path.join(r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\", \"modelresultImg\")\n",
    "print(f\"결과 이미지가 다음 경로에 저장되었습니다: {default_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "094791c9-4c56-42b1-a3c1-6e9b9b90b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Python_Pytorch_Workspace\\Jupyter_Test\\dog-cat2.png: 640x608 1 cat, 1 dog, 43.0ms\n",
      "Speed: 4.0ms preprocess, 43.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "Results saved to \u001b[1mruns\\segment\\predict2\u001b[0m\n",
      "결과 이미지가 다음 경로에 저장되었습니다: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg_Dogs\n"
     ]
    }
   ],
   "source": [
    "# YOLOv8 모델로 예측 실행 및 저장 경로 변경\n",
    "# 사용자 정의 YOLOv8 모델 로드\n",
    "# model = YOLO(\"dogs_best.pt\")\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model.predict(\n",
    "    source=r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\dog-cat2.png\",  # 테스트 이미지 경로\n",
    "    save=True,  # 결과 저장 활성화\n",
    "    save_dir=r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg_Dogs\"  # 결과 저장 경로\n",
    ")\n",
    "\n",
    "print(f\"결과 이미지가 다음 경로에 저장되었습니다: D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg_Dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8b458-42d6-4b07-b521-36b0b373137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 변수 설정\n",
    "image_path = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\Aquarium_DataSet\\test\\images\\IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg\"\n",
    "save_dir = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\modelresultImg\"\n",
    "\n",
    "# 결과 저장 경로가 없으면 생성\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# YOLO 모델 로드 및 예측\n",
    "model = YOLO(\"best.pt\")\n",
    "results = model.predict(source=image_path, save=True, save_dir=save_dir)\n",
    "\n",
    "# 결과 경로 확인\n",
    "print(\"Results saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8e91ed-e20a-49dd-adc7-917546f9d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 49.7ms\n",
      "Speed: 3.0ms preprocess, 49.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 27.0ms\n",
      "Speed: 5.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 5.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 5.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.5ms\n",
      "Speed: 4.3ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 teddy bear, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 1 teddy bear, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.1ms\n",
      "Speed: 2.5ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 dog, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detection completed. Output video saved at D:\\Python_Pytorch_Workspace\\Jupyter_Test\\output_강아지영상.mp4\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow  # Colab 전용 imshow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "# model = YOLO(\"yolov8n.pt\")  # Nano 모델 사용\n",
    "# 사용자 정의 YOLOv8 모델 로드\n",
    "# model = YOLO(\"best.pt\")\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# 비디오 파일 경로\n",
    "video_path = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\강아지영상.mp4\"\n",
    "\n",
    "# 출력 비디오 설정\n",
    "output_path = r\"D:\\Python_Pytorch_Workspace\\Jupyter_Test\\output_강아지영상.mp4\"\n",
    "\n",
    "# 비디오 캡처 초기화\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file.\")\n",
    "    exit()\n",
    "\n",
    "# 비디오 속성 읽기\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "# 출력 비디오 초기화\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# 프레임 단위로 객체 탐지 수행\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:  # 비디오의 끝에 도달한 경우\n",
    "        break\n",
    "\n",
    "    # YOLOv8을 사용하여 객체 탐지\n",
    "    results = model.predict(source=frame, save=False, conf=0.5)\n",
    "\n",
    "    # 탐지 결과 시각화\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # 탐지 결과를 출력 비디오에 저장\n",
    "    out.write(annotated_frame) \n",
    "\n",
    "    # Jupyter Notebook에서 프레임 표시 (매 30 프레임마다)\n",
    "    if frame_count % 30 == 0:  # 너무 자주 표시하면 성능 저하\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))  # BGR -> RGB 변환\n",
    "        plt.axis('off')  # 축 숨기기\n",
    "        plt.show()\n",
    "    frame_count += 1\n",
    "\n",
    "# 리소스 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Detection completed. Output video saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23b436-3c3a-4afd-b71b-73867292fd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79543b-8499-49db-808d-74456ef840fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
